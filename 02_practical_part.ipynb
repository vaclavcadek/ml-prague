{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical example using an Exhaust gas temperature simulator\n",
    "\n",
    "See https://docs.google.com/presentation/d/16vMcof96I43LyeatzuaEJ_OKftEuNUQ7dvMUiPa1dK8/edit#slide=id.g24cf74510db_0_625 for more details"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary setup for Google Colab & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.numerical_simulator as simulator\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import  ConstantKernel, RBF\n",
    "from src import plots\n",
    "from src import utils\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Simulator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated variable: **Maximal exhaust gas temperature during take off of an airplane. [K]**\n",
    "\n",
    "Input variables:\n",
    "\n",
    "| name | description | unit |\n",
    "| --- | --- | --- |\n",
    "| *oat* | Outside air temperature at take off | [K] |\n",
    "| *max_speed* | Maximal flight speed at take off | [km/h] |\n",
    "| *altitude* | Airport altitude at take off | [m] |\n",
    "| *humidity* | Air humidity at take off | [%] |\n",
    "| *air_density* | Air density at take off | [kg/m3] |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim = 200\n",
    "egt_threshold = 1250"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's generate a dataframe of input values\n",
    "**Task**\n",
    "- Use a `simulator` (imported as `import src.numerical_simulator as simulator`) and it's function `generate_input_data()` to generate 200 (`num_sim`) different set of conditions, assign them to `X` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK start ###\n",
    "X = ...\n",
    "### TASK end ###\n",
    "X.sample(5).round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can use our complex and heavy simulator to generate the true values of the target variable\n",
    "\n",
    "**Task**\n",
    "- Use a `simulator` (imported as `import src.numerical_simulator as simulator`) and it's function `simulate_max_egt()` to generate 200 (`num_sim`) different targets given the input conditions `X`, assign them to `y` variable.\n",
    "- Note the potential simulation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK start ###\n",
    "y = ...\n",
    "### TASK end ###\n",
    "print(f\"Output range is [{round(y.min(),2)} ; {round(y.max(), 2)}]\")\n",
    "y.sample(5).rename('egt').to_frame().round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's identify dangerous observations where temperature is too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_risk_obs = (y > egt_threshold).sum()\n",
    "print(f\"Number of obs that are potentially dangerous: {nbr_risk_obs} out of {num_sim}\\n\")\n",
    "rng_max = y.argmax()\n",
    "x_max = X.loc[rng_max,]\n",
    "print(\"The worst observation of all:\")\n",
    "x_max.round(2).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**\n",
    "\n",
    "- Select the risky observations and assign them to variable `X_risk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_risk = X[y > egt_threshold]\n",
    "print(\"Only oat and air_density are influential on the risk area.\")\n",
    "X_risk.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gaussian Process Regression\n",
    "First we need to scale the input data before applying the Kriging algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**\n",
    "- Use a simulator to generate set of test data (10000) as `X_test` and `y_test`\n",
    "- Rescale `X_test` using already fitted scaler and assign the result to a variable `X_test_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim_test = 10000\n",
    "### TASK start ###\n",
    "X_test = ...\n",
    "y_test = ...\n",
    "### TASK start ###\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: \n",
    "- Build a composite kernel (combined through `*`) consisting of:\n",
    "   -  isotrophic (~ shared params across input dimensions) `ConstantKernel`, set `constant_value_bounds=(1, 1e6)`\n",
    "   -  anisotrophic (each dimension has own lengthscale parameter, it's not shared across dimensions) `RBF` kernel, set `length_scale_bounds=(1, 1e4)`\n",
    "   -  (use initial value of each param 1.0)\n",
    "- Fit a GP model using this kernel.\n",
    "- Print learned kernel's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(\n",
    "    np.repeat(1.0, X.shape[1]), length_scale_bounds=(0.1, 1e4)\n",
    ")\n",
    "gaussian_process = GaussianProcessRegressor(\n",
    "    kernel=kernel, random_state=0, n_restarts_optimizer=5, normalize_y=True\n",
    ")\n",
    "gaussian_process.fit(X_scaled, y)\n",
    "gaussian_process.kernel_.get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task** \n",
    "\n",
    "-  Use a fitted `gaussian_process` to get predictions for `X_scaled` (please note that GP returns mean and standard_deviation (or variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, y_std = gaussian_process.predict(X_scaled, return_std=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the Kriging estimators.\n",
    "\n",
    "We create 1D slices of the 5D space. For each slice, we select one observation at which we keep 4 dimensions constant.\n",
    "We then inspect what will happen to our target's prediction if we change the values of the remaining dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "vis_index = rng.choice(X_scaled.shape[0], size=1, replace=False)\n",
    "x_predict = X_scaled[vis_index, :]\n",
    "y_predict = y[vis_index]\n",
    "x_axis = np.linspace(-2, 2, 101)\n",
    "plots.show_multiD_slices_plots(X, x_predict, x_axis, gaussian_process, y_predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what is wrong with this?\n",
    "- It is not Leave one out error but instead it's test set error\n",
    "- Why it's possible to divide by `y_range=100` to get percentages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = 100\n",
    "y_test_pred = gaussian_process.predict(X_test_scaled)\n",
    "mse_test = (((y_test - y_test_pred)/y_range)**2)\n",
    "mae_test = abs(y_test - y_test_pred)/y_range\n",
    "\n",
    "rmse_rounded = round(np.mean(mse_test) ** 0.5 * 100, 2)\n",
    "mae_rounded = round(np.mean(mae_test) * 100, 2)\n",
    "print(f\"Leave-one-out error metrics: \\n\"\n",
    "      f\"    RMSE: {rmse_rounded}% \\n\"\n",
    "      f\"    MAE:  {mae_rounded}%.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out Approach\n",
    "\n",
    "As every observation is precious, we do not want to throw away any, which means that we cannot do a standard train-test set approach.\n",
    "\n",
    "First let's generate some simulations, scale them, and build the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim = 50\n",
    "X = utils.generate_input_data(num_sim)\n",
    "y = utils.simulate_max_egt(X)\n",
    "print(f\"Design space dimensions: {X.shape}\")\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Kriging model, train it, and store hyperparameters for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(\n",
    "    np.repeat(1.0, X.shape[1]), length_scale_bounds=(1, 1e4)\n",
    ")\n",
    "gaussian_process = GaussianProcessRegressor(\n",
    "    kernel=kernel, random_state=0, n_restarts_optimizer=5, normalize_y=True\n",
    ")\n",
    "\n",
    "gaussian_process.fit(X_scaled, y)\n",
    "\n",
    "k1_LOO, k2_LOO = (\n",
    "    gaussian_process.kernel_.k1.constant_value,\n",
    "    gaussian_process.kernel_.k2.length_scale,\n",
    ")\n",
    "kernel_LOO = ConstantKernel(k1_LOO, constant_value_bounds=\"fixed\") * RBF(length_scale=k2_LOO, length_scale_bounds=\"fixed\")\n",
    "gaussian_process_LOO = GaussianProcessRegressor(kernel=kernel_LOO, optimizer=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the collection of LOO train/test and build Kriging model in each case.\n",
    "\n",
    "**Question**: what is wrong with this?\n",
    "- why they are training on whole dataset? That is not LOO approach...\n",
    "- Try to comment out `gaussian_process_LOO.fit(X_train, y_train)` and uncomment the prepared section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.split(X_scaled, y)\n",
    "y_pred_list = []\n",
    "mse_list = []\n",
    "mae_list = []\n",
    "for i, (train_index, test_index) in enumerate(loo.split(X_scaled)):\n",
    "     X_train = X_scaled[train_index]\n",
    "     X_test = X_scaled[test_index]\n",
    "     y_train = y[train_index]\n",
    "     y_test = y[test_index]\n",
    "     gaussian_process_LOO.fit(X_train, y_train)\n",
    "     #kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(np.repeat(1.0, X.shape[1]), length_scale_bounds=(1, 1e4))\n",
    "     #gaussian_process_LOO = GaussianProcessRegressor(kernel=kernel, random_state=0, n_restarts_optimizer=5, normalize_y=True)\n",
    "     #gaussian_process_LOO.fit(X_train, y_train)\n",
    "    \n",
    "     y_test_pred = gaussian_process_LOO.predict(X_test, return_std=False)\n",
    "     y_pred_list.append(y_test_pred[0])\n",
    "     mse_list.append(((y_test - y_test_pred) / y_test)  ** 2)\n",
    "     mae_list.append(abs((y_test - y_test_pred) / y_test))\n",
    "\n",
    "rmse_rounded = round(np.mean(mse_list) ** 0.5 * 100, 2)\n",
    "mae_rounded = round(np.mean(mae_list) * 100, 2)\n",
    "print(f\"Leave-one-out error metrics: \\n\"\n",
    "      f\"    relative RMSE: {rmse_rounded}% \\n\"\n",
    "      f\"    relative MAE:  {mae_rounded}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Design - Local Improvement\n",
    "\n",
    "Generate inputs, scale data, make their copy for enrichment, generate grid.\n",
    "\n",
    "Generate test data (larger set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = 100\n",
    "num_sim = 30\n",
    "X = utils.generate_input_data(num_sim)\n",
    "y = utils.simulate_max_egt(X)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "X_rich = X_scaled.copy()\n",
    "y_rich = y.copy()\n",
    "\n",
    "num_sim_test = 10000\n",
    "X_test = utils.generate_input_data(num_sim_test)\n",
    "y_test = utils.simulate_max_egt(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "grid_1D = np.linspace(-2, 2, 11)\n",
    "X_grid_scaled = np.array(np.meshgrid(*([grid_1D] * 5))).T.reshape(-1, X.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate loop to add points to the design sequentially\n",
    "IMPORTANT: do not recalculate the hyperparameters after each added point but only after each added batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "- Use surrogate model (GP) to evaluate whole grid to receive predictions with uncertainties, store it to `kriging_mean` and `kriging_std`.\n",
    "\n",
    "**Task 2** \n",
    "- pick a new point with the highest uncertainty (please note it's received in scaled space)\n",
    "- inverse transform it (don't forget to reshape to correct shape such as `.reshape(1, 5)`)\n",
    "- use `utils.simulate_max_egt` to receive new `new_y` (don't forget it expects DataFrame such as `pd.DataFrame(new_x_unscaled, columns=X.columns)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_nbr = 6\n",
    "batch_size = 5\n",
    "for iter_batch in range(batch_nbr):\n",
    "    # Build Kriging model - estimate hyperparameters for the whole batch\n",
    "    if iter_batch == 0:\n",
    "        kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(np.repeat(1.0, X.shape[1]), length_scale_bounds=(1, 1e6))\n",
    "    # In case a gpr has already be fitted, re-use last hyperparameters as initial steps for upcoming fitting\n",
    "    else:\n",
    "        kernel = ConstantKernel(k1_batch, constant_value_bounds=(1, 1e6)) * RBF(k2_batch, length_scale_bounds=(1, 1e6))\n",
    "\n",
    "    gaussian_process = GaussianProcessRegressor(kernel=kernel, random_state=0, n_restarts_optimizer=5, normalize_y=True)\n",
    "    gaussian_process.fit(X_rich, y_rich)\n",
    "\n",
    "    # Save resulting hyperparameters to fasten the model build in upcoming batch of points\n",
    "    k1_batch, k2_batch = gaussian_process.kernel_.k1.constant_value, gaussian_process.kernel_.k2.length_scale\n",
    "    kernel_batch = ConstantKernel(k1_batch, constant_value_bounds=\"fixed\") * RBF(length_scale=k2_batch, length_scale_bounds=\"fixed\")\n",
    "    gaussian_process_batch = GaussianProcessRegressor(kernel=kernel_batch, optimizer=None)\n",
    "    gaussian_process_batch.fit(X_rich, y_rich)\n",
    "    ### TASK 1 start ###\n",
    "    kriging_mean, kriging_std = ...\n",
    "    ### TASK 1 end ###\n",
    "\n",
    "    # add \"batch_size\" points according to prediction with the same Kriging hyperparameters\n",
    "    for iter in range(batch_size):\n",
    "        # Pick point with highest Kriging error and add it to the design\n",
    "        ### TASK 2 start ###    \n",
    "        new_y = ...\n",
    "        ### TASK 2 end ###\n",
    "        X_rich = np.append(X_rich, [new_x], axis=0)\n",
    "        y_rich = np.append(y_rich, new_y)\n",
    "\n",
    "        # Re-run Kriging model w/ enriched design\n",
    "        gaussian_process_batch.fit(X_rich, y_rich)\n",
    "        kriging_mean, kriging_std = gaussian_process_batch.predict(X_grid_scaled, return_std=True)\n",
    "\n",
    "    # measure how metrics improve after every batch\n",
    "    y_test_pred = gaussian_process_batch.predict(X_test_scaled, return_std=False)\n",
    "    mse_test = (((y_test - y_test_pred))**2)\n",
    "    mae_test = abs(y_test - y_test_pred)\n",
    "            \n",
    "    rmse_rounded = round(np.mean(mse_test) ** 0.5, 2)\n",
    "    mae_rounded = round(np.mean(mae_test), 2)\n",
    "    print(f\"Test set error metrics: \\nRMSE: {rmse_rounded} \\nMAE:  {mae_rounded}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Design - EGO\n",
    "\n",
    "First, let's setup the data, scale the data and make copy for enrichment. Build grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EGT_threshold = 1250\n",
    "\n",
    "num_sim = 30\n",
    "X = utils.generate_input_data(num_sim)\n",
    "y = utils.simulate_max_egt(X)\n",
    "print(f\"Design space dimensions: {X.shape}\")\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "X_rich = X_scaled.copy()\n",
    "y_rich = y.copy()\n",
    "\n",
    "grid_1D = np.linspace(-2, 2, 11)\n",
    "X_grid_scaled = np.array(np.meshgrid(*([grid_1D] * 5))).T.reshape(-1, X.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the current maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_max_x = X_rich[y_rich.argmax()]\n",
    "current_max = y_rich.max()\n",
    "\n",
    "print(f\"Current max is y={current_max} for X:\")\n",
    "current_max_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Kriging model, estimate hyperparameters, improve maximum sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "- Use surrogate model (GP) to evaluate whole grid to receive predictions with uncertainties, store it to `mean_prediction` and `std_prediction`.\n",
    "\n",
    "**Task 2**  \n",
    "- In utils there is an acquisition function `utils.expected_improvement()` prepared for you, use it to obtain estimates for every point in the grid. Use `?` to see the functions signature.\n",
    "- pick a new point with the highest EI (please note it's received in scaled space)\n",
    "- inverse transform it (don't forget to reshape to correct shape such as `.reshape(1, 5)`)\n",
    "- use `utils.simulate_max_egt` to receive new `new_y` (don't forget it expects DataFrame such as `pd.DataFrame(new_x_unscaled, columns=X.columns)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 20\n",
    "\n",
    "for iter in range(n_iter):\n",
    "    if iter == 0:\n",
    "        kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(np.repeat(1.0, X.shape[1]), length_scale_bounds=(1, 1e6))\n",
    "    else:\n",
    "        kernel = ConstantKernel(k1, constant_value_bounds=(1, 1e6)) * RBF(k2, length_scale_bounds=(1, 1e6))\n",
    "    gaussian_process = GaussianProcessRegressor(kernel=kernel, random_state=0, n_restarts_optimizer=20, normalize_y=True)\n",
    "    gaussian_process.fit(X_rich, y_rich)\n",
    "\n",
    "    ### TASK 1 starts ###\n",
    "    mean_prediction, std_prediction = ...\n",
    "    ### TASK 1 ends ###\n",
    "    \n",
    "    k1, k2 = (\n",
    "        gaussian_process.kernel_.k1.constant_value,\n",
    "        gaussian_process.kernel_.k2.length_scale,\n",
    "    )\n",
    "\n",
    "    ## TASK 2 start ###\n",
    "    new_y = ...\n",
    "    ## TASK 2 end ###\n",
    "    X_rich = np.append(X_rich, [new_x], axis=0)\n",
    "    y_rich = np.append(y_rich, new_y)\n",
    "\n",
    "    current_max_x = X_rich[y_rich.argmax()]\n",
    "    current_max = y_rich.max()\n",
    "    print(f\"Current maximum: \\n\" f\"    X: {current_max_x} \\n\" f\"    y:  {current_max}.\")\n",
    "\n",
    "print(f\"Final maximum: \\n\" f\"    X: {current_max_x} \\n\" f\"    y:  {current_max}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Kriging model for the whole batch and check all observations that are above the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(1.0, constant_value_bounds=(1, 1e6)) * RBF(np.repeat(1.0, X.shape[1]), length_scale_bounds=(1, 1e6))\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, random_state=0, n_restarts_optimizer=5, normalize_y=True)\n",
    "gaussian_process.fit(X_rich, y_rich)\n",
    "mean_prediction, std_prediction = gaussian_process.predict(X_grid_scaled, return_std=True)\n",
    "\n",
    "bad_X_pred = pd.DataFrame(X_grid_scaled[mean_prediction > EGT_threshold], columns=X.columns)\n",
    "\n",
    "indices_bad_prob = (1 - norm.cdf((EGT_threshold - mean_prediction) / std_prediction)) > 0.2\n",
    "bad_X_prob = pd.DataFrame(X_grid_scaled[indices_bad_prob], columns=X.columns)\n",
    "\n",
    "display(bad_X_pred.describe())\n",
    "display(bad_X_prob.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Reading\n",
    "-\n",
    "Much better resource with more sensible naming and notation on the topic can be found here: https://distill.pub/2020/bayesian-optimization/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
